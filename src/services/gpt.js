import dotenv from "dotenv";
dotenv.config();

import OpenAI from "openai";
import { logError, logInfo } from "../utils/logger.js";
import { sendMessage } from "./whatsapp.js";

import {
    getConversationHistory,
    addConversation
} from "../database/database.js";

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

// ==================================================
// üß† GPT PREMIUM ‚Äî Com mem√≥ria otimizada
// ==================================================
export async function respostaGPT(phone, mensagem) {
    try {
        logInfo("‚û°Ô∏è Preparando GPT com mem√≥ria otimizada", { phone });

        // 1Ô∏è‚É£ Buscar hist√≥rico completo
        let history = await getConversationHistory(phone);

        // 2Ô∏è‚É£ Limitar ao hist√≥rico mais recente (20 intera√ß√µes)
        if (history.length > 20) {
            history = history.slice(history.length - 20);
        }

        // 3Ô∏è‚É£ Comprimir hist√≥rico longo (reduz custo)
        const resumoHistorico = gerarResumoSeNecessario(history);

        // 4Ô∏è‚É£ Montar prompt final
        const messages = [
            {
                role: "system",
                content:
                    "Voc√™ √© o assistente oficial Pecu√°ria Pro. " +
                    "Seu objetivo √© ajudar criadores com respostas claras, pr√°ticas " +
                    "e objetivas sobre pecu√°ria, dietas, manejo, reprodu√ß√£o, sa√∫de e gest√£o. " +
                    "Nunca responda de forma gen√©rica ou vaga."
            },

            // Resumo comprimido (se existir)
            ...(resumoHistorico
                ? [{ role: "system", content: `Resumo da conversa anterior: ${resumoHistorico}` }]
                : []),

            // Hist√≥rico original
            ...history.map(h => ({
                role: h.role,
                content: h.message
            })),

            // Pergunta atual
            { role: "user", content: mensagem }
        ];

        // 5Ô∏è‚É£ Chamar modelo com suporte a hist√≥rico
        const completion = await openai.chat.completions.create({
            model: "gpt-4.1-mini",
            messages,
            temperature: 0.5
        });

        const resposta = completion.choices[0].message.content;

        // Seguran√ßa: evita resposta vazia
        const respostaFinal = resposta?.trim() || "N√£o consegui entender a pergunta.";

        // 6Ô∏è‚É£ Salvar resposta no hist√≥rico
        await addConversation(phone, "assistant", respostaFinal);

        // 7Ô∏è‚É£ Enviar ao WhatsApp
        await sendMessage(phone, respostaFinal);

        return respostaFinal;

    } catch (err) {
        logError(err, {
            local: "respostaGPT",
            phone,
            mensagem
        });

        await sendMessage(
            phone,
            "‚ö†Ô∏è A IA encontrou um erro. Tente novamente em instantes."
        );

        return null;
    }
}

// ==================================================
// üîß Fun√ß√£o que comprime hist√≥rico para reduzir custo
// ==================================================
function gerarResumoSeNecessario(history) {
    if (history.length < 10) return null;

    const resumo = history
        .slice(0, history.length - 8)
        .map(h => `${h.role === "user" ? "Usu√°rio" : "Assistente"}: ${h.message}`)
        .join(" | ");

    return resumo.length > 800 ? resumo.slice(0, 800) + "..." : resumo;
}
