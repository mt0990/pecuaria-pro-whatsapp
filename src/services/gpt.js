import dotenv from "dotenv";
dotenv.config();

import OpenAI from "openai";
import { logError, logInfo } from "../utils/logger.js";

import {
    getConversationHistory,
    addConversation
} from "../database/database.js";

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

// ==================================================
// üß† GPT PREMIUM ‚Äî Com mem√≥ria otimizada (SEM DUPLICAR MENSAGEM)
// ==================================================
export async function respostaGPT(phone, mensagem) {
    try {
        logInfo("‚û°Ô∏è Preparando GPT com mem√≥ria otimizada", { phone });

        // 1Ô∏è‚É£ Buscar hist√≥rico
        let history = await getConversationHistory(phone);

        // 2Ô∏è‚É£ Limitar ao mais recente
        if (history.length > 20) {
            history = history.slice(history.length - 20);
        }

        // 3Ô∏è‚É£ Resumo opcional
        const resumoHistorico = gerarResumoSeNecessario(history);

        // 4Ô∏è‚É£ Prompt do ChatGPT
        const messages = [
            {
                role: "system",
                 content:
                    "Voc√™ √© o assistente oficial Pecu√°ria Pro. " +
                    "Responda SOMENTE √† pergunta atual do usu√°rio. " +
                    "N√ÉO continue conversas anteriores, N√ÉO ofere√ßa sugest√µes extras, " +
                    "e N√ÉO gere respostas longas demais. " +
                    "Se o usu√°rio pedir valores, informe valores. " +
                    "Se pedir explica√ß√£o, explique, mas sempre de forma curta, clara e direta. " +
                    "N√ÉO invente ingredientes, N√ÉO monte dietas completas se n√£o for pedido. " +
                    "Foque APENAS no que foi perguntado AGORA."
            },

            ...(resumoHistorico
                ? [{ role: "system", content: `Resumo da conversa anterior: ${resumoHistorico}` }]
                : []),

            ...history.map(h => ({
                role: h.role,
                content: h.message
            })),

            { role: "user", content: mensagem }
        ];

        // 5Ô∏è‚É£ Chamada GPT
        const completion = await openai.chat.completions.create({
            model: "gpt-4.1-mini",
            messages,
            temperature: 0.5
        });

        const resposta = completion.choices[0].message.content;
        const respostaFinal = resposta?.trim() || "N√£o consegui entender a pergunta.";

        // 6Ô∏è‚É£ Salvar hist√≥rico
        await addConversation(phone, "assistant", respostaFinal);

        // 7Ô∏è‚É£ IMPORTANTE: N√ÉO enviar aqui ‚Äî apenas retornar
        return respostaFinal;

    } catch (err) {
        logError(err, {
            local: "respostaGPT",
            phone,
            mensagem
        });

        return "‚ö†Ô∏è A IA encontrou um erro. Tente novamente em instantes.";
    }
}

// ==================================================
// üîß Redu√ß√£o de hist√≥rico
// ==================================================
function gerarResumoSeNecessario(history) {
    if (history.length < 10) return null;

    const resumo = history
        .slice(0, history.length - 8)
        .map(h => `${h.role === "user" ? "Usu√°rio" : "Assistente"}: ${h.message}`)
        .join(" | ");

    return resumo.length > 800 ? resumo.slice(0, 800) + "..." : resumo;
}
